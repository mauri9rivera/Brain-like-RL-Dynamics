{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e818a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import json \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import motornet as mn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d623ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model, losses, env):\n",
    "\n",
    "    #Create model directory\n",
    "    base_dir = os.path.join(\"outputs\", \"savedmodels\")\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    date_dir = os.path.join(base_dir, today)\n",
    "    os.makedirs(date_dir, exist_ok=True)\n",
    "    model_dir = os.path.join(date_dir, model.name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    weight_file = os.path.join(model_dir, \"weights\")\n",
    "    log_file = os.path.join(model_dir, \"log.json\")\n",
    "    cfg_file = os.path.join(model_dir, \"cfg.json\")\n",
    "\n",
    "    #Saving model weights, training history and environment configuration dictionary\n",
    "    th.save(model.state_dict(), weight_file)\n",
    "    with open(log_file, 'w') as file:\n",
    "        json.dump(losses, file)\n",
    "    cfg = env.get_save_config()\n",
    "    with open(cfg_file, 'w') as file:\n",
    "        json.dump(cfg, file)\n",
    "\n",
    "    print(f\"Done saving model's weights, training history and env in {model_dir}\")\n",
    "\n",
    "def load_environment(cfg_file, verbose=False):\n",
    "\n",
    "    with open(cfg_file, 'r') as file:\n",
    "        cfg = json.load(file)\n",
    "\n",
    "    if verbose:\n",
    "        for k1, v1 in cfg.items():\n",
    "            if isinstance(v1, dict):\n",
    "                print(k1 + \":\")\n",
    "                for k2, v2 in v1.items():\n",
    "                    if type(v2) is dict:\n",
    "                        print(\"\\t\\t\" + k2 + \":\")\n",
    "                        for k3, v3 in v2.items():\n",
    "                            print(\"\\t\\t\\t\\t\" + k3 + \": \", v3)\n",
    "                    else:\n",
    "                        print(\"\\t\\t\" + k2 + \": \", v2)\n",
    "            else:\n",
    "                print(k1 + \": \", v1)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "def load_model(env, model_class, weight_file, device='cpu'):\n",
    "\n",
    "    model = model_class(env.observation_space, env.action_space, lambda epoch: 3e-5,device)\n",
    "    state_dict = th.load(weight_file)\n",
    "    model.load_state_dict(state_dict)  # Don't overwrite model here!\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def plot_simulations(xy, target_xy):\n",
    "    \n",
    "    plotor = mn.plotor.plot_pos_over_time    \n",
    "    target_x = target_xy[:, -1, 0]\n",
    "    target_y = target_xy[:, -1, 1]\n",
    "\n",
    "    plt.figure(figsize=(10,3))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.ylim([-1.1, 1.1])\n",
    "    plt.xlim([-1.1, 1.1])\n",
    "    plotor(axis=plt.gca(), cart_results=xy)\n",
    "    plt.scatter(target_x, target_y)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.xlim([-2, 2])\n",
    "    plotor(axis=plt.gca(), cart_results=xy - target_xy[:, :, :2])\n",
    "    plt.axhline(0, c=\"grey\")\n",
    "    plt.axvline(0, c=\"grey\")\n",
    "    plt.xlabel(\"X distance to target\")\n",
    "    plt.ylabel(\"Y distance to target\")\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_pretrained(policy, env, batch_size):\n",
    "    \"\"\"Evaluation function with hidden state management\"\"\"\n",
    "    # Reset hidden states\n",
    "    policy.hidden_states = policy.actor.init_hidden(batch_size)\n",
    "    \n",
    "    # Initialize environment\n",
    "    obs, info = env.reset(options={\"batch_size\": batch_size})\n",
    "    terminated = False\n",
    "    xy = [info[\"states\"][\"fingertip\"][:, None, :]]\n",
    "    tg = [info[\"goal\"][:, None, :]]\n",
    "\n",
    "    # Run evaluation episode\n",
    "    while not terminated:\n",
    "        action, _, _ = policy(obs, deterministic=True)  # Deterministic actions\n",
    "        obs, _, terminated, _, info = env.step(action)\n",
    "        xy.append(info[\"states\"][\"fingertip\"][:, None, :])\n",
    "        tg.append(info[\"goal\"][:, None, :])\n",
    "\n",
    "    # Plot results\n",
    "    xy = th.cat(xy, axis=1).detach().numpy()\n",
    "    tg = th.cat(tg, axis=1).detach().numpy()\n",
    "    plot_simulations(xy=xy, target_xy=tg)\n",
    "\n",
    "def plot_loss(losses):\n",
    "    \"\"\"Plot training loss\"\"\"\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.semilogy(losses)\n",
    "    plt.xlabel(\"Batch #\")\n",
    "    plt.ylabel(\"L1 Loss\")\n",
    "    plt.title(\"Pretraining Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_center_out(trajectories):\n",
    "    \"\"\"Plot end-effector trajectories for all trials.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for traj in trajectories:\n",
    "        plt.plot(traj[:, 0], traj[:, 1], alpha=0.3, linewidth=0.5)\n",
    "    plt.xlabel('X Position', fontsize=12)\n",
    "    plt.ylabel('Y Position', fontsize=12)\n",
    "    plt.title('Center-Out Reaching Trajectories', fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_task(env, n_batch=1, is_obstacle=False):\n",
    "    \"\"\"Visualizes all start positions and targets with proper labels and sizing.\"\"\"\n",
    "    # Reset environment and get positions\n",
    "    _, info = env.reset(options={\"batch_size\": n_batch})\n",
    "    starts = info[\"states\"][\"fingertip\"].cpu().numpy()[:, :2]\n",
    "    targets = info[\"goal\"].cpu().numpy()[:, :2]\n",
    "\n",
    "    # Create plot with locked axes\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(-0.75, 0.75)\n",
    "    ax.set_ylim(-0.5, 1)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # Add obstacle rectangle if requested\n",
    "    if is_obstacle:\n",
    "        rect_params = (-0.3, 0.3, 0.2, 0.4)  # xmin, ymin, xmax, ymax\n",
    "        width = rect_params[2] - rect_params[0]\n",
    "        height = rect_params[3] - rect_params[1]\n",
    "        obstacle = Rectangle(\n",
    "            (rect_params[0], rect_params[1]),\n",
    "            width,\n",
    "            height,\n",
    "            facecolor='#CCCCCC',\n",
    "            edgecolor='none',\n",
    "            alpha=1.0,\n",
    "            zorder=1  # Ensure rectangle is behind other elements\n",
    "        )\n",
    "        ax.add_patch(obstacle)\n",
    "\n",
    "    # Plot ALL starts and targets first with labels\n",
    "    ax.scatter(starts[:, 0], starts[:, 1], \n",
    "               color='blue', alpha=0.7, s=100, label='Start', zorder=3)\n",
    "    ax.scatter(targets[:, 0], targets[:, 1], \n",
    "               color='red', alpha=0.7, s=50, label='Target', zorder=3)\n",
    "\n",
    "    # Add connection lines\n",
    "    for i in range(n_batch):\n",
    "        ax.plot([starts[i, 0], targets[i, 0]],\n",
    "                [starts[i, 1], targets[i, 1]], \n",
    "                'k--', linewidth=1, alpha=0.5, zorder=2)\n",
    "\n",
    "    # Add labels and grid\n",
    "    ax.set_xlabel('X position (m)')\n",
    "    ax.set_ylabel('Y position (m)')\n",
    "    ax.set_title(f'Start/Target Positions (n={n_batch})')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_trajectories(trajectories, start_pos=None, targets=None):\n",
    "    \"\"\"\n",
    "    Visualize trajectories for any type of reaching task\n",
    "    \n",
    "    Args:\n",
    "        trajectories: List of numpy arrays containing end effector positions\n",
    "        start_pos: (Optional) Initial position(s) as numpy array (single or per-trial)\n",
    "        targets: (Optional) Target positions as numpy array (single or per-trial)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot all trajectories\n",
    "    for i, traj in enumerate(trajectories):\n",
    "        # Main trajectory path\n",
    "        plt.plot(traj[:, 0], traj[:, 1], alpha=0.4, linewidth=0.8, c='blue')\n",
    "        \n",
    "        # Plot start and end markers\n",
    "        start = traj[0] if start_pos is None else start_pos[i] if len(start_pos) > 1 else start_pos\n",
    "        end = traj[-1] if targets is None else targets[i] if len(targets) > 1 else targets\n",
    "        \n",
    "        plt.scatter(start[0], start[1], c='green', s=60, marker='o', edgecolors='k')\n",
    "        plt.scatter(end[0], end[1], c='red', s=60, marker='s', edgecolors='k')\n",
    "\n",
    "    # Add labels and decorations\n",
    "    plt.title(\"Movement Trajectories\", fontsize=14)\n",
    "    plt.xlabel(\"X Position (m)\", fontsize=12)\n",
    "    plt.ylabel(\"Y Position (m)\", fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    # Create legend\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label='Start', \n",
    "                  markersize=10, markerfacecolor='g', markeredgecolor='k'),\n",
    "        plt.Line2D([0], [0], marker='s', color='w', label='Target', \n",
    "                  markersize=10, markerfacecolor='r', markeredgecolor='k')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def get_neural_activity(env, policy, n_trials=1000):\n",
    "    \"\"\"\n",
    "    Collect the neural activities and trajectories of a network during an experimental task.\n",
    "\n",
    "    - env: The environment doing the task\n",
    "    - model: The network from which to extract the neural activity and trajectories\n",
    "    - n_trials: The number of trials to perform\n",
    "    \"\"\"\n",
    "\n",
    "    neural_activities = []\n",
    "    trajectories = []\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "\n",
    "        # Reset hidden states\n",
    "        policy.hidden_states = policy.actor.init_hidden(1)\n",
    "\n",
    "        # Initialize environment\n",
    "        obs, info = env.reset(seed= 1, options={\"batch_size\": 1})\n",
    "        xy = [info[\"states\"][\"fingertip\"][:, None, :]]\n",
    "        tg = [info[\"goal\"][:, None, :]]\n",
    "\n",
    "        done = False\n",
    "        trial_activity = []\n",
    "        trial_traj = []\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            action, _, _ = policy(obs, deterministic=True)\n",
    "            \n",
    "            # Capture hidden state and trajectory\n",
    "            trial_activity.append(policy.hidden_states)\n",
    "            \n",
    "            # Step environment\n",
    "            next_obs, _, done, _, info = env.step(action)\n",
    "            obs_tensor = next_obs[0] \n",
    "            trial_traj.append(info[\"states\"][\"fingertip\"][:, None, :])\n",
    "            \n",
    "        # Store trial data\n",
    "        neural_activities.append(np.array([x.detach().numpy() for x in trial_activity]))\n",
    "        trajectories.append(np.array([x.detach().numpy() for x in trial_traj]))\n",
    "    \n",
    "    return neural_activities, trajectories\n",
    "\n",
    "def extract_leading_components(neural_activities, n_components=20):\n",
    "    \"\"\"Extract top PCA components from neural activity.\"\"\"\n",
    "    # Concatenate all trials\n",
    "    data = np.vstack([trial for trial in neural_activities])[:, 0, 0, :]\n",
    "\n",
    "    # Normalize data (z-score)\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(normalized_data)\n",
    "    \n",
    "    return {\n",
    "        'components': pca.components_,\n",
    "        'explained_variance': pca.explained_variance_ratio_,\n",
    "        'cumulative_variance': np.cumsum(pca.explained_variance_ratio_),\n",
    "        'transformed_data': pca.transform(normalized_data)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cfcc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your effector (for instance, using RigidTendonArm26 with MujocoHillMuscle)\n",
    "arm = mn.effector.RigidTendonArm26(muscle=mn.muscle.MujocoHillMuscle())\n",
    "\n",
    "from environment import RandomTargetReach\n",
    "from networks import *\n",
    "# Instantiate the custom reach environment.\n",
    "#env = create_defaultReachTask(arm)\n",
    "#env = CustomReachEnv(effector=arm)\n",
    "env = RandomTargetReach(\n",
    "effector=arm,\n",
    "obs_noise=0.0,\n",
    "proprioception_noise=0.0,\n",
    "vision_noise=0.0,\n",
    "action_noise=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30871bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_task(env, 100, False)\n",
    "net = load_model(env, ACNetwork, '../outputs/savedmodels/2025-04-20/DefaultPPO/weights')\n",
    "#evaluate_pretrained(net, env, 10)\n",
    "neural_activity, trajectories = get_neural_activity(env, net, 100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e8aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = extract_leading_components(neural_activity, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67873798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsa_repo.DSA.dmd import DMD\n",
    "from dsa_repo.DSA.simdist import SimilarityTransformDist\n",
    "from dsa_repo.DSA.dsa import DSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmd parameters, all others are default for now.\n",
    "n_delays = 50\n",
    "delay_interval = 20\n",
    "rank = 30\n",
    "device = 'cpu' #change this if you have a GPU! Otherwise it will be slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ba5201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Hankel matrix ...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#playing around with optimization here, we don't necessarily need the metric to converge to \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#get good clustering!\u001b[39;00m\n\u001b[0;32m      3\u001b[0m dsa \u001b[38;5;241m=\u001b[39m DSA([pcs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_data\u001b[39m\u001b[38;5;124m'\u001b[39m], pcs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_data\u001b[39m\u001b[38;5;124m'\u001b[39m]],n_delays\u001b[38;5;241m=\u001b[39mn_delays,rank\u001b[38;5;241m=\u001b[39mrank,delay_interval\u001b[38;5;241m=\u001b[39mdelay_interval,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,device\u001b[38;5;241m=\u001b[39mdevice,iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mdsa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mauri\\OneDrive\\Documents\\Udem\\Winter 2025\\MAT 6215\\Brain-like_RL_Dynamics\\src\\dsa_repo\\DSA\\dsa.py:292\u001b[0m, in \u001b[0;36mDSA.fit_score\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dmd_sets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdmds:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dmd \u001b[38;5;129;01min\u001b[39;00m dmd_sets:\n\u001b[1;32m--> 292\u001b[0m         \u001b[43mdmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore()\n",
      "File \u001b[1;32mc:\\Users\\mauri\\OneDrive\\Documents\\Udem\\Winter 2025\\MAT 6215\\Brain-like_RL_Dynamics\\src\\dsa_repo\\DSA\\dmd.py:459\u001b[0m, in \u001b[0;36mDMD.fit\u001b[1;34m(self, data, n_delays, delay_interval, rank, rank_thresh, rank_explained_variance, lamb, device, verbose, steps_ahead)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m verbose\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_hankel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_delays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_svd()\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduced_rank_reg:\n",
      "File \u001b[1;32mc:\\Users\\mauri\\OneDrive\\Documents\\Udem\\Winter 2025\\MAT 6215\\Brain-like_RL_Dynamics\\src\\dsa_repo\\DSA\\dmd.py:203\u001b[0m, in \u001b[0;36mDMD.compute_hankel\u001b[1;34m(self, data, n_delays, delay_interval)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_delays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_delays \u001b[38;5;28;01mif\u001b[39;00m n_delays \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m n_delays\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay_interval \u001b[38;5;28;01mif\u001b[39;00m delay_interval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m delay_interval\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mH \u001b[38;5;241m=\u001b[39m embed_signal_torch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_delays, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay_interval)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\mauri\\miniconda3\\envs\\BrainRL\\lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#playing around with optimization here, we don't necessarily need the metric to converge to \n",
    "#get good clustering!\n",
    "dsa = DSA([pcs['transformed_data'], pcs['transformed_data']],n_delays=n_delays,rank=rank,delay_interval=delay_interval,verbose=True,device=device,iters=100,lr=1e-2)\n",
    "similarities = dsa.fit_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BrainRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
