{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ca215b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import json \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import motornet as mn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import math\n",
    "from torch.distributions import Normal\n",
    "from gymnasium import Wrapper\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "329fb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamics_analysis import *\n",
    "from environment import *\n",
    "from networks import *\n",
    "from neural_activity import *\n",
    "from utils import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2151c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1LossCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, log_path=\"./logs/\"):\n",
    "        super().__init__(verbose)\n",
    "        self.log_path = log_path\n",
    "        self.losses = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Info dict for each parallel env\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "\n",
    "        for info in infos:\n",
    "            if 'goal' in info and 'fingertip' in info:\n",
    "                goal = np.array(info['goal'])\n",
    "                fingertip = np.array(info['fingertip'])\n",
    "\n",
    "                l1_loss = np.abs(goal - fingertip).sum()\n",
    "                self.losses.append(l1_loss)\n",
    "\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"L1 loss: {l1_loss:.4f}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        # Optional: Save the loss values for later\n",
    "        os.makedirs(self.log_path, exist_ok=True)\n",
    "        np.save(os.path.join(self.log_path, \"l1_losses.npy\"), np.array(self.losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d306b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotorNetBatchLoadWrapper(Wrapper):\n",
    "    \"\"\"\n",
    "    Ensures actions have shape (batch, n_muscles) and supplies\n",
    "    default zero loads for endpoint and joints on every step().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env: mn.environment.RandomTargetReach):\n",
    "        super().__init__(env)\n",
    "        # Probe once to figure out load shapes:\n",
    "        obs, info = env.reset(options={\"batch_size\": 1})\n",
    "        geom_state = info[\"states\"][\"geometry\"]  # (1, n_points, 2)\n",
    "        joint_state = info[\"states\"][\"joint\"]    # (1, n_joints)\n",
    "\n",
    "        # For endpoint_load we need one value per coordinate axis (x,y)\n",
    "        self.endpoint_dim = geom_state.shape[2]  # = 2\n",
    "        # For joint_load we need one per joint\n",
    "        self.n_joints = info[\"states\"][\"joint\"].shape[1] // 2\n",
    "        print(f\"Detected: endpoint_dim={self.endpoint_dim}, n_joints={self.n_joints}, n_muscles={self.n_muscles}\")\n",
    "        # For actions we need one per muscle\n",
    "        self.n_muscles   = env.n_muscles\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.array(action, dtype=np.float32)\n",
    "        if action.ndim == 1:\n",
    "            action = action[None, :]  # shape (1, act_dim)\n",
    "\n",
    "        batch = action.shape[0]\n",
    "\n",
    "        endpoint_load = np.zeros((batch, self.endpoint_dim), dtype=np.float32)\n",
    "        joint_load = np.zeros((batch, self.n_joints), dtype=np.float32)\n",
    "\n",
    "        obs, _, terminated, truncated, info = self.env.step(\n",
    "            action=action,\n",
    "            endpoint_load=endpoint_load,\n",
    "            joint_load=joint_load\n",
    "        )\n",
    "\n",
    "        target = info[\"goal\"]\n",
    "        fingertip = info[\"states\"][\"fingertip\"]\n",
    "        reward = -np.linalg.norm(fingertip - target, axis=1)  # shape (batch,)\n",
    "\n",
    "        # Use the first sample\n",
    "        obs = obs[0]\n",
    "        reward = float(reward[0])\n",
    "        terminated = bool(terminated)\n",
    "        truncated = bool(truncated)\n",
    "        info = {k: (v[0] if isinstance(v, np.ndarray) and v.shape[0] == batch else v) for k, v in info.items()}\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomACPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
    "        device = kwargs.get('device', 'cpu')\n",
    "        kwargs.pop('device')\n",
    "        super().__init__(observation_space, action_space, lr_schedule, **kwargs)\n",
    "        self._build_network(device)\n",
    "        self._hidden_states = None\n",
    "\n",
    "    def _build_network(self, device):\n",
    "        input_dim = self.observation_space.shape[0]\n",
    "        self.action_dim = self.action_space.shape[0]\n",
    "        self.hidden_dim = 64  # Match your GRU hidden size\n",
    "\n",
    "        # Actor (GRU-based) and Critic\n",
    "        self.actor = Policy(input_dim, self.hidden_dim, self.action_dim, device)\n",
    "        self.critic = Critic(input_dim, device)\n",
    "\n",
    "    def reset_hidden(self, batch_size=1):\n",
    "        self._hidden_states = self.actor.init_hidden(batch_size)\n",
    "\n",
    "    def forward(self, obs, deterministic=False):\n",
    "        if self._hidden_states is None or self._hidden_states.size(1) != obs.shape[0]:\n",
    "            self.reset_hidden(obs.shape[0])\n",
    "        \n",
    "        mean, new_hidden = self.actor(obs, self._hidden_states)\n",
    "        self._hidden_states = new_hidden.detach()\n",
    "\n",
    "        # Define action distribution\n",
    "        std = th.ones_like(mean) * 0.1  # or learnable\n",
    "        dist = th.distributions.Normal(mean, std)\n",
    "\n",
    "        # Sample action\n",
    "        actions = dist.mean if deterministic else dist.sample()\n",
    "        log_probs = dist.log_prob(actions).sum(dim=-1, keepdim=True)\n",
    "\n",
    "        values = self.critic(obs)\n",
    "\n",
    "        return actions, values, log_probs\n",
    "\n",
    "    def evaluate_actions(self, obs, actions):\n",
    "        if self._hidden_states is None or self._hidden_states.size(1) != obs.shape[0]:\n",
    "            self.reset_hidden(obs.shape[0])\n",
    "\n",
    "        mean, new_hidden = self.actor(obs, self._hidden_states)\n",
    "        self._hidden_states = new_hidden.detach()\n",
    "\n",
    "        std = th.ones_like(mean) * 0.1\n",
    "        dist = th.distributions.Normal(mean, std)\n",
    "\n",
    "        log_probs = dist.log_prob(actions).sum(dim=-1, keepdim=True)\n",
    "        entropy = dist.entropy().sum(dim=-1, keepdim=True)\n",
    "        values = self.critic(obs)\n",
    "\n",
    "        if values.ndim == 1:\n",
    "            values = values.unsqueeze(1)\n",
    "\n",
    "        return values, log_probs, entropy\n",
    "    \n",
    "    \n",
    "def PPO_train():\n",
    "    # Create the MotorNet environment\n",
    "    effector = mn.effector.RigidTendonArm26(muscle=mn.muscle.MujocoHillMuscle())\n",
    "    env = mn.environment.RandomTargetReach(effector=effector, max_ep_duration=5.)\n",
    "\n",
    "    # 2. Wrap it\n",
    "    wrapped_env = MotorNetBatchLoadWrapper(env)\n",
    "\n",
    "    #sanity check\n",
    "    print(\"Wrapped action_space:\", wrapped_env.action_space)\n",
    "    print(\"Wrapped observation_space:\", wrapped_env.observation_space)\n",
    "    \n",
    "    # Instantiate the custom PPO model\n",
    "    model = PPO(\n",
    "        CustomACPolicy,\n",
    "        wrapped_env,\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=10000,  # Adjust based on your environment's requirements\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        verbose=1,\n",
    "        policy_kwargs={\n",
    "            'device': 'cuda:0' if th.cuda.is_available() else 'cpu'\n",
    "        }\n",
    "    )\n",
    "    callback = L1LossCallback(verbose=1)\n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=1000, callback=callback)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cdcfaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: endpoint_dim=6, n_joints=2, n_muscles=6\n",
      "Wrapped action_space: Box(0.0, 1.0, (6,), float32)\n",
      "Wrapped observation_space: Box(-inf, inf, (16,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 501      |\n",
      "|    ep_rew_mean     | -180     |\n",
      "| time/              |          |\n",
      "|    fps             | 160      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_model = PPO_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f92c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pretrained(policy, env, batch_size):\n",
    "    \"\"\"Evaluation function with hidden state management\"\"\"\n",
    "    # Reset hidden states\n",
    "    policy.hidden_states = policy.actor.init_hidden(batch_size)\n",
    "    \n",
    "    # Initialize environment\n",
    "    obs, info = env.reset(options={\"batch_size\": batch_size})\n",
    "    terminated = np.zeros(batch_size, dtype=bool)\n",
    "    xy = [info[\"states\"][\"fingertip\"][:, None, :]]\n",
    "    tg = [info[\"goal\"][:, None, :]]\n",
    "\n",
    "    # Run evaluation episode\n",
    "    while not terminated.all():\n",
    "        obs = obs.to(policy.actor.device)  # Move observation to the same device as the model\n",
    "        action, _, _, _ = policy(obs, deterministic=True)\n",
    "        xy.append(info[\"states\"][\"fingertip\"][:, None, :])\n",
    "        tg.append(info[\"goal\"][:, None, :])\n",
    "\n",
    "    # Plot results\n",
    "    xy = th.cat(xy, axis=1).detach().numpy()\n",
    "    tg = th.cat(tg, axis=1).detach().numpy()\n",
    "    plot_simulations(xy=xy, target_xy=tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1aba1285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.n_muscles to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.n_muscles` for environment variables or `env.get_wrapper_attr('n_muscles')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: endpoint_dim=6, n_joints=2, n_muscles=6\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 2. Wrap it\u001b[39;00m\n\u001b[32m      6\u001b[39m wrapped_env = MotorNetBatchLoadWrapper(env)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mevaluate_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\Udem\\Winter 2025\\MAT 6215\\Brain-like-RL-Dynamics\\src\\utils.py:108\u001b[39m, in \u001b[36mevaluate_pretrained\u001b[39m\u001b[34m(policy, env, batch_size)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Run evaluation episode\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminated.all():\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     action, _, _, _ = \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Deterministic actions\u001b[39;00m\n\u001b[32m    109\u001b[39m     obs, _, terminated, _, info = env.step(action)\n\u001b[32m    110\u001b[39m     xy.append(info[\u001b[33m\"\u001b[39m\u001b[33mstates\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfingertip\u001b[39m\u001b[33m\"\u001b[39m][:, \u001b[38;5;28;01mNone\u001b[39;00m, :])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mCustomACPolicy.forward\u001b[39m\u001b[34m(self, obs, deterministic)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hidden_states.size(\u001b[32m1\u001b[39m) != obs.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset_hidden(obs.shape[\u001b[32m0\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m mean, new_hidden = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mself\u001b[39m._hidden_states = new_hidden.detach()\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Define action distribution\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\Udem\\Winter 2025\\MAT 6215\\Brain-like-RL-Dynamics\\src\\networks.py:48\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, x, h0)\u001b[39m\n\u001b[32m     44\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected parameter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h0):\n\u001b[32m     49\u001b[39m     y, h = \u001b[38;5;28mself\u001b[39m.gru(x.unsqueeze(\u001b[32m1\u001b[39m), h0)  \n\u001b[32m     50\u001b[39m     u = \u001b[38;5;28mself\u001b[39m.sigmoid(\u001b[38;5;28mself\u001b[39m.fc(y.squeeze(\u001b[32m1\u001b[39m))) \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\BrainRL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1100\u001b[39m, in \u001b[36mGRU.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28mself\u001b[39m.check_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     result = _VF.gru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m._flat_weights, \u001b[38;5;28mself\u001b[39m.bias,\n\u001b[32m   1104\u001b[39m                      \u001b[38;5;28mself\u001b[39m.num_layers, \u001b[38;5;28mself\u001b[39m.dropout, \u001b[38;5;28mself\u001b[39m.training, \u001b[38;5;28mself\u001b[39m.bidirectional)\n",
      "\u001b[31mRuntimeError\u001b[39m: Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0"
     ]
    }
   ],
   "source": [
    "# Create the MotorNet environment\n",
    "effector = mn.effector.RigidTendonArm26(muscle=mn.muscle.MujocoHillMuscle())\n",
    "env = mn.environment.RandomTargetReach(effector=effector, max_ep_duration=5.)\n",
    "\n",
    "# 2. Wrap it\n",
    "wrapped_env = MotorNetBatchLoadWrapper(env)\n",
    "evaluate_pretrained(trained_model.policy, wrapped_env, batch_size=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BrainRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
